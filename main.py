import os
import argparse
import random
import numpy as np
import torch
import torch.optim as optim
from tqdm import tqdm
import time
import logging  # <=== 新增 1: 导入 logging 模块
import sys  # <=== 新增 2: 导入 sys 模块
import matplotlib.pyplot as plt  # <=== 新增 3: 导入 matplotlib

from torch.utils.data import DataLoader
from src.dataloader.dataset import MedicalDataSets
from albumentations.augmentations import transforms
from albumentations.core.composition import Compose
from albumentations import RandomRotate90, Resize
import src.utils.losses as losses
from src.utils.util import AverageMeter
from src.utils.metrics import iou_score

from src.network.conv_based.CMUNet import CMUNet
from src.network.conv_based.CMUNet_MSHFFA import CMUNet_MSHFFA
from src.network.conv_based.CMUNet_ECA import CMUNet_ECA
from src.network.conv_based.U_Net import U_Net
from src.network.conv_based.AttU_Net import AttU_Net
from src.network.conv_based.UNeXt import UNext
from src.network.conv_based.UNetplus import ResNet34UnetPlus
from src.network.conv_based.UNet3plus import UNet3plus
from src.network.conv_based.CMUNeXt import cmunext

from src.network.transfomer_based.transformer_based_network import get_transformer_based_model

from src.network.hybrid_based.Mobile_U_ViT import mobileuvit, mobileuvit_l


def seed_torch(seed):
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
    random.seed(seed)
    np.random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)


parser = argparse.ArgumentParser()
parser.add_argument('--model', type=str, default="Mobile_U_ViT",
                    choices=["Mobile_U_ViT", "CMUNeXt", "CMUNet","CMUNet_MSHFFA", "CMUNet_ECA","AttU_Net", "TransUnet", "R2U_Net", "U_Net",
                             "UNext", "UNetplus", "UNet3plus", "SwinUnet", "MedT", "TransUnet"], help='model')
parser.add_argument('--base_dir', type=str, default="./data/busi", help='dir')
parser.add_argument('--train_file_dir', type=str, default="busi_train.txt", help='dir')
parser.add_argument('--val_file_dir', type=str, default="busi_val.txt", help='dir')
parser.add_argument('--base_lr', type=float, default=0.01, help='segmentation network learning rate')
parser.add_argument('--batch_size', type=int, default=4, help='batch_size per gpu')
parser.add_argument('--epoch', type=int, default=300, help='train epoch')
parser.add_argument('--img_size', type=int, default=256, help='img size of per batch')
parser.add_argument('--num_classes', type=int, default=1, help='seg num_classes')
parser.add_argument('--seed', type=int, default=41, help='random seed')
# <=== 修改 4: 修正拼写错误 (arser -> parser)
parser.add_argument('--save_dir', type=str, default="./checkpoint", help='directory to save the best model')
args = parser.parse_args()
seed_torch(args.seed)


def get_model(args):
    if args.model == "CMUNet":
        model = CMUNet(output_ch=args.num_classes).cuda()
    elif args.model == "CMUNet_MSHFFA":  # <-- 新增分支
        model = CMUNet_MSHFFA(output_ch=args.num_classes).cuda()
    elif args.model == "CMUNet_ECA":  # <--- 在这里添加新分支
        model = CMUNet_ECA(output_ch=args.num_classes).cuda()
    elif args.model == "CMUNeXt":
        model = cmunext(num_classes=args.num_classes).cuda()
    elif args.model == "U_Net":
        model = U_Net(output_ch=args.num_classes).cuda()
    elif args.model == "AttU_Net":
        model = AttU_Net(output_ch=args.num_classes).cuda()
    elif args.model == "UNext":
        model = UNext(output_ch=args.num_classes).cuda()
    elif args.model == "UNetplus":
        model = ResNet34UnetPlus(num_class=args.num_classes).cuda()
    elif args.model == "UNet3plus":
        model = UNet3plus(n_classes=args.num_classes).cuda()
    elif args.model == "Mobile_U_ViT":
        model = mobileuvit(out_channel=args.num_classes).cuda()
    else:
        model = get_transformer_based_model(parser=parser, model_name=args.model, img_size=args.img_size,
                                            num_classes=args.num_classes, in_ch=3).cuda()
    return model


def getDataloader(args):
    img_size = args.img_size
    if args.model == "SwinUnet":
        img_size = 224
    train_transform = Compose([
        RandomRotate90(),
        transforms.Flip(),
        Resize(img_size, img_size),
        transforms.Normalize(),
    ])

    val_transform = Compose([
        Resize(img_size, img_size),
        transforms.Normalize(),
    ])
    db_train = MedicalDataSets(base_dir=args.base_dir, split="train",
                               transform=train_transform, train_file_dir=args.train_file_dir,
                               val_file_dir=args.val_file_dir)
    db_val = MedicalDataSets(base_dir=args.base_dir, split="val", transform=val_transform,
                             train_file_dir=args.train_file_dir, val_file_dir=args.val_file_dir)
    # <=== 修改 5: 将 print 替换为 logging.info
    logging.info("train num:{}, val num:{}".format(len(db_train), len(db_val)))

    trainloader = DataLoader(db_train, batch_size=args.batch_size, shuffle=True, num_workers=8, pin_memory=False)
    valloader = DataLoader(db_val, batch_size=args.batch_size, shuffle=False, num_workers=4)

    return trainloader, valloader


def main(args):
    # <=== 新增 5: 确保保存目录存在 (使用 exist_ok=True 避免已存在时出错)
    os.makedirs(args.save_dir, exist_ok=True)

    # <=== 新增 6: 配置 logging
    log_file_path = os.path.join(args.save_dir, 'training_log.txt')
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(message)s',
        handlers=[
            logging.FileHandler(log_file_path),  # 保存到文件
            logging.StreamHandler(sys.stdout)  # 输出到控制台
        ]
    )
    # =================================

    base_lr = args.base_lr

    trainloader, valloader = getDataloader(args=args)

    model = get_model(args)

    # <=== 修改 6: 将 print 替换为 logging.info
    logging.info("Args: {}".format(args))  # 打印所有参数到日志
    logging.info("train file dir:{} val file dir:{}".format(args.train_file_dir, args.val_file_dir))

    optimizer = optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=0.0001)
    criterion = losses.__dict__['BCEDiceLoss']().cuda()

    # <=== 修改 7: 将 print 替换为 logging.info
    logging.info("{} iterations per epoch".format(len(trainloader)))
    best_iou = 0
    iter_num = 0
    max_epoch = args.epoch

    train_loss_history = []
    train_iou_history = []
    val_loss_history = []
    val_iou_history = []

    max_iterations = len(trainloader) * max_epoch

    start_time = time.time()

    for epoch_num in range(max_epoch):
        model.train()
        avg_meters = {'loss': AverageMeter(),
                      'iou': AverageMeter(),
                      'val_loss': AverageMeter(),
                      'val_iou': AverageMeter(),
                      'val_SE': AverageMeter(),
                      'val_PC': AverageMeter(),
                      'val_F1': AverageMeter(),
                      'val_ACC': AverageMeter()}

        # (您修改的部分)
        train_bar = tqdm(trainloader, desc=f"Epoch {epoch_num}/{max_epoch} [Train]")

        for i_batch, sampled_batch in enumerate(train_bar):
            img_batch, label_batch = sampled_batch['image'], sampled_batch['label']
            img_batch, label_batch = img_batch.cuda(), label_batch.cuda()

            outputs = model(img_batch)

            loss = criterion(outputs, label_batch)
            iou, dice, _, _, _, _, _ = iou_score(outputs, label_batch)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            lr_ = base_lr * (1.0 - iter_num / max_iterations) ** 0.9
            for param_group in optimizer.param_groups:
                param_group['lr'] = lr_

            iter_num = iter_num + 1
            avg_meters['loss'].update(loss.item(), img_batch.size(0))
            avg_meters['iou'].update(iou, img_batch.size(0))

            train_bar.set_postfix(loss=avg_meters['loss'].avg, iou=avg_meters['iou'].avg)

        model.eval()
        with torch.no_grad():
            val_bar = tqdm(valloader, desc=f"Epoch {epoch_num}/{max_epoch} [Val  ]")

            for i_batch, sampled_batch in enumerate(val_bar):
                img_batch, label_batch = sampled_batch['image'], sampled_batch['label']
                img_batch, label_batch = img_batch.cuda(), label_batch.cuda()
                output = model(img_batch)
                loss = criterion(output, label_batch)
                iou, _, SE, PC, F1, _, ACC = iou_score(output, label_batch)
                avg_meters['val_loss'].update(loss.item(), img_batch.size(0))
                avg_meters['val_iou'].update(iou, img_batch.size(0))
                avg_meters['val_SE'].update(SE, img_batch.size(0))
                avg_meters['val_PC'].update(PC, img_batch.size(0))
                avg_meters['val_F1'].update(F1, img_batch.size(0))
                avg_meters['val_ACC'].update(ACC, img_batch.size(0))

                val_bar.set_postfix(val_loss=avg_meters['val_loss'].avg, val_iou=avg_meters['val_iou'].avg)

        # <=== 修改 8: 将 print 替换为 logging.info
        elapsed_time = time.time() - start_time
        elapsed_str = time.strftime('%H:%M:%S', time.gmtime(elapsed_time))

        logging.info(
            'epoch [%d/%d] (Total time: %s)  train_loss : %.4f, train_iou: %.4f - val_loss %.4f - val_iou %.4f - val_SE %.4f - '
            'val_PC %.4f - val_F1 %.4f - val_ACC %.4f '
            % (epoch_num, max_epoch, elapsed_str,
               avg_meters['loss'].avg, avg_meters['iou'].avg,
               avg_meters['val_loss'].avg, avg_meters['val_iou'].avg, avg_meters['val_SE'].avg,
               avg_meters['val_PC'].avg, avg_meters['val_F1'].avg, avg_meters['val_ACC'].avg))
        # <=========================================

        train_loss_history.append(avg_meters['loss'].avg)
        train_iou_history.append(avg_meters['iou'].avg)
        val_loss_history.append(avg_meters['val_loss'].avg)
        val_iou_history.append(avg_meters['val_iou'].avg)

        if avg_meters['val_iou'].avg > best_iou:
            # <=== 修改 9: 使用 args.save_dir 来构建路径
            # 目录已在 main 开头创建，这里无需检查
            save_file_path = os.path.join(args.save_dir, '{}_model.pth'.format(args.model))
            torch.save(model.state_dict(), save_file_path)

            best_iou = avg_meters['val_iou'].avg

            # <=== 修改 10: 将 print 替换为 logging.info
            logging.info(f"=> saved best model to {save_file_path}")

    # <=== 修改 11: 将 print 替换为 logging.info，并使用 args.save_dir
    # 目录已在 main 开头创建，这里无需检查
    logging.info("Saving metric history...")
    np.save(os.path.join(args.save_dir, f'{args.model}_train_loss.npy'), np.array(train_loss_history))
    np.save(os.path.join(args.save_dir, f'{args.model}_train_iou.npy'), np.array(train_iou_history))
    np.save(os.path.join(args.save_dir, f'{args.model}_val_loss.npy'), np.array(val_loss_history))
    np.save(os.path.join(args.save_dir, f'{args.model}_val_iou.npy'), np.array(val_iou_history))

    # <=== 新增 7: 绘制并保存训练曲线图
    logging.info("Saving training curve plots...")
    epochs = range(1, max_epoch + 1)

    # 绘制 Loss 曲线
    plt.figure()
    plt.plot(epochs, train_loss_history, 'b', label='Training Loss')
    plt.plot(epochs, val_loss_history, 'r', label='Validation Loss')
    plt.title(f'{args.model} - Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(args.save_dir, f'{args.model}_loss_plot.png'))
    plt.close()

    # 绘制 IoU 曲线
    plt.figure()
    plt.plot(epochs, train_iou_history, 'b', label='Training IoU')
    plt.plot(epochs, val_iou_history, 'r', label='Validation IoU')
    plt.title(f'{args.model} - Training and Validation IoU')
    plt.xlabel('Epochs')
    plt.ylabel('IoU')
    plt.legend()
    plt.savefig(os.path.join(args.save_dir, f'{args.model}_iou_plot.png'))
    plt.close()
    # =================================
    # 保存最后一个 epoch 的模型权重
    last_model_path = os.path.join(args.save_dir, '{}_model_last.pth'.format(args.model))
    logging.info(f"=> Saving last epoch model to {last_model_path}")
    torch.save(model.state_dict(), last_model_path)
    # ++++++++++++++++ 添加结束 ++++++++++++++++

    logging.info("Training Finished!")
    return "Training Finished!"


if __name__ == "__main__":
    main(args)


# python main.py --model CMUNet --base_dir ./data/isic2018 --train_file_dir isic2018_train.txt --val_file_dir isic2018_val.txt --base_lr 0.01 --epoch 300 --batch_size 8

#  cd ~/autodl-tmp/cmu-net

# python main.py --model CMUNet --base_dir ./data/busi --train_file_dir busi_train3.txt --val_file_dir busi_val3.txt --save_dir ./checkpoint/busi-3-1 --base_lr 0.005 --epoch 300 --batch_size 8
